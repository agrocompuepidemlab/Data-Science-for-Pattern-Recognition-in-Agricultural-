{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h3>This notebook contains a Lasso Regression. Our dataset consist of weather and other variables corresponding to sugar cane crops, the goal is to predict values of sucrose production.</h3>"
      ],
      "metadata": {
        "id": "lYtt9TRT7r2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading libraries and dataset"
      ],
      "metadata": {
        "id": "u9URKjoBJHhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CteFghfYSYVT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "plt.style.use(['seaborn'])\n",
        "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"tab10\"))\n",
        "sns.set_style('ticks')\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "# import statsmodels.api as sm\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.stats import normaltest\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, quantile_transform\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import multiprocessing\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyIdCX9UIgV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f46673b-6cf9-4680-ca55-dabd87ac4d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/data.xlsx'\n",
        "weather_data_final=pd.read_excel(path)\n",
        "file = ' no suelo'"
      ],
      "metadata": {
        "id": "ZQBPVrNfI0dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQrwO_oALJ4"
      },
      "source": [
        "#  Normalization\n",
        "---\n",
        "\n",
        "Perform a normality test on our target variables (*Sac, Sac Campo* and *Sac % Caña*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiRIGGz4AcTa"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize=(25,10))\n",
        "ax[0].hist(weather_data_final['Sac'], color='r')\n",
        "ax[0].set_title('Histogram of Sac')\n",
        "ax[1].hist(weather_data_final['Sac % Caña'],color='g')\n",
        "ax[1].set_title('Histogram of Sac % Caña')\n",
        "ax[2].hist(weather_data_final['Sac Campo'])\n",
        "ax[2].set_title('Histogram of Sac Campo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTnJUWWtCS4g"
      },
      "outputs": [],
      "source": [
        "def normal_test(target):\n",
        "\tstat, p = normaltest(weather_data_final[target])\n",
        "\talpha =0.05\n",
        "\tif p > alpha:\n",
        "\t\tprint(target + ' looks Gaussian')\n",
        "\telse:\n",
        "\t\tprint(target + ' does not look Gaussian')\n",
        "normal_test('Sac')\n",
        "normal_test('Sac % Caña')\n",
        "normal_test('Sac Campo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "150bCFuEEnK0"
      },
      "source": [
        "There is no conclusion about the normality.\n",
        "\n",
        "Using preprocessing techniques such as *Quantile transformation* we can normalize our targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkAdVateIG-n"
      },
      "outputs": [],
      "source": [
        "def normalization(target):\n",
        "    y=weather_data_final[target]\n",
        "    y_trans = quantile_transform(y.to_frame(), output_distribution=\"normal\", copy=True)\n",
        "    return y_trans\n",
        "\n",
        "weather_data_final['sac_trans'] = normalization('Sac')\n",
        "weather_data_final['sac_caña_trans']= normalization('Sac % Caña')\n",
        "weather_data_final['sac_campo_trans'] = normalization('Sac Campo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXP4MlZUIZgm"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize=(25,10))\n",
        "ax[0].hist(weather_data_final['sac_trans'], color='r')\n",
        "ax[0].set_title('Histogram of Sac after transformation')\n",
        "ax[1].hist(weather_data_final['sac_caña_trans'],color='g')\n",
        "ax[1].set_title('Histogram of Sac % Caña after transformation')\n",
        "ax[2].hist(weather_data_final['sac_campo_trans'])\n",
        "ax[2].set_title('Histogram of Sac Campo after transformation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGJ7eSZYtnxx"
      },
      "source": [
        "Info about target variables after the transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwcGqABFtZ1L"
      },
      "outputs": [],
      "source": [
        "weather_data_final[['sac_trans', 'sac_campo_trans', 'sac_caña_trans']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jFm2J5ouCvb"
      },
      "source": [
        "Testing normality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuAMhgZVHQC3"
      },
      "outputs": [],
      "source": [
        "normal_test('sac_trans')\n",
        "normal_test('sac_caña_trans')\n",
        "normal_test('sac_campo_trans')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1KJe-QElM3E"
      },
      "outputs": [],
      "source": [
        "weather_data_final.drop(['Sac', 'Sac % Caña', 'Sac Campo'], axis=1, inplace=True) #remove old targets to left only normal targets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test split\n",
        "\n",
        "Train-test split 80/20"
      ],
      "metadata": {
        "id": "fOAljEPIPM0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = weather_data_final.drop(['sac_trans', 'sac_caña_trans', 'sac_campo_trans'], axis=1)\n",
        "y = weather_data_final[['sac_trans', 'sac_caña_trans', 'sac_campo_trans']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "CnZdQLXjPJy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and training pipeline\n"
      ],
      "metadata": {
        "id": "9pwn73cPNc3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We are going to use one hot encoder for categorical variables and standarization for numerical."
      ],
      "metadata": {
        "id": "-24LqFDcTCjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars = ['tmprda', 'TIPO COS','Con Sin Mad', 'nm_cndcion', 'PRODUCTO', 'VAR']\n",
        "num_vars =  X_train.select_dtypes(include=['float64', 'int']).columns.to_list()"
      ],
      "metadata": {
        "id": "qi4ykFe7Ohz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para las variables numéricas\n",
        "numeric_transformer = Pipeline(\n",
        "                        steps=[('scaler', StandardScaler())]\n",
        "                      )\n",
        "\n",
        "# Transformaciones para las variables categóricas\n",
        "categorical_transformer = Pipeline(\n",
        "                            steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))]\n",
        "                          )\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "                    transformers=[\n",
        "                        ('numeric', numeric_transformer, num_vars),\n",
        "                        ('cat', categorical_transformer, cat_vars)\n",
        "                    ],\n",
        "                    remainder='passthrough'\n",
        "                )\n",
        "\n",
        "# Se combinan los pasos de preprocesado y el modelo en un mismo pipeline.\n",
        "pipe = Pipeline([('preprocessing', preprocessor),\n",
        "                 ('modelo', Lasso(max_iter=2000))])\n",
        "\n",
        "# Definimos espacio de busqueda para el param alpha de Lasso\n",
        "param_distributions = {'modelo__alpha': np.linspace(0, 1, 100)}\n",
        "\n",
        "grid = RandomizedSearchCV(\n",
        "        estimator  = pipe,\n",
        "        param_distributions = param_distributions,\n",
        "        n_iter     = 10,\n",
        "        scoring    = 'neg_mean_absolute_error',\n",
        "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
        "        cv         = RepeatedKFold(n_splits = 5, n_repeats = 3),\n",
        "        refit      = True,\n",
        "        verbose    = 0,\n",
        "        random_state = 123,\n",
        "        return_train_score = True\n",
        "       )"
      ],
      "metadata": {
        "id": "bzUb9shqP1H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sac"
      ],
      "metadata": {
        "id": "slqNS6jeZCFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'sac_trans'\n",
        "grid.fit(X = X_train, y = y_train[target])"
      ],
      "metadata": {
        "id": "6IRLWMivZD-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_sac = pd.DataFrame(grid.cv_results_)\n",
        "resultados_sac.filter(regex = '(param.*|mean_t|std_t)')\\\n",
        "    .drop(columns = 'params')\\\n",
        "    .sort_values('mean_test_score', ascending = False)\\\n",
        "    .head(3)"
      ],
      "metadata": {
        "id": "8KpBXbxrRPL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico resultados validación cruzada para cada hiperparámetro\n",
        "# ==============================================================================\n",
        "def plot_error(resultados):\n",
        "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
        "    hiperparametro = 'param_modelo__alpha'\n",
        "    resultados = resultados.sort_values(hiperparametro, ascending = False)\n",
        "    metrica    = grid.scoring\n",
        "\n",
        "    resultados.plot(hiperparametro, 'mean_train_score', ax=ax)\n",
        "    resultados.plot(hiperparametro, 'mean_test_score', ax=ax)\n",
        "    ax.fill_between(resultados[hiperparametro].astype(int),\n",
        "                    resultados['mean_train_score'] + resultados['std_train_score'],\n",
        "                    resultados['mean_train_score'] - resultados['std_train_score'],\n",
        "                    alpha=0.2)\n",
        "    ax.fill_between(resultados[hiperparametro].astype(int),\n",
        "                    resultados['mean_test_score'] + resultados['std_test_score'],\n",
        "                    resultados['mean_test_score'] - resultados['std_test_score'],\n",
        "                    alpha=0.2)\n",
        "    ax.legend()\n",
        "    ax.set_title('Evolución del error CV')\n",
        "    ax.set_ylabel(metrica);\n",
        "plot_error(resultados_sac)"
      ],
      "metadata": {
        "id": "VW8zf960SAjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo final\n",
        "# ==============================================================================\n",
        "modelo_final = grid.best_estimator_\n",
        "predicciones = modelo_final.predict(X = X_test)\n",
        "mae_err = mean_absolute_error(\n",
        "            y_true  = y_test[target],\n",
        "            y_pred  = predicciones,\n",
        "          )\n",
        "r2_err = r2_score(y_true  = y_test[target],\n",
        "            y_pred  = predicciones)\n",
        "print(f\"El error (MAE) de test es: {mae_err}\")\n",
        "print(f\"El r2 de test es: {r2_err}\")"
      ],
      "metadata": {
        "id": "9MVwe_b1Sar8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(time, series,i, format=\"-\", start=0, end=None):\n",
        "    # fig, axis = plt.figure(figsize=(20,10))\n",
        "    plt.plot(time[start:end], series[start:end], format,label=i)\n",
        "    plt.xlabel(\"Unseen Samples\")\n",
        "    plt.ylabel(\"Sucrose Field\")\n",
        "    # plt.legend()"
      ],
      "metadata": {
        "id": "h10VPoBMYjho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(22,5))\n",
        "plot_series(y_test.reset_index().index, y_test[target], \"True\")\n",
        "plot_series(y_test.reset_index().index, predicciones,'Predicted')\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.title('Sac true vs predicted')\n",
        "fig = plt.gcf()\n",
        "plt.show()\n",
        "fig.savefig('true vs predic sac' + file + '.png', bboxs='tight')"
      ],
      "metadata": {
        "id": "1g1kvaVIYv74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sac Campo"
      ],
      "metadata": {
        "id": "DANp6JSlb5dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'sac_campo_trans'\n",
        "grid.fit(X = X_train, y = y_train[target])"
      ],
      "metadata": {
        "id": "tifH_HoQb8Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_sac = pd.DataFrame(grid.cv_results_)\n",
        "resultados_sac.filter(regex = '(param.*|mean_t|std_t)')\\\n",
        "    .drop(columns = 'params')\\\n",
        "    .sort_values('mean_test_score', ascending = False)\\\n",
        "    .head(3)"
      ],
      "metadata": {
        "id": "GZ-xAvi6b8Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico resultados validación cruzada para cada hiperparámetro\n",
        "# ==============================================================================\n",
        "\n",
        "plot_error(resultados_sac)"
      ],
      "metadata": {
        "id": "PNXWTi5Ab8Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo final\n",
        "# ==============================================================================\n",
        "modelo_final = grid.best_estimator_\n",
        "predicciones = modelo_final.predict(X = X_test)\n",
        "mae_err = mean_absolute_error(\n",
        "            y_true  = y_test[target],\n",
        "            y_pred  = predicciones,\n",
        "          )\n",
        "r2_err = r2_score(y_true  = y_test[target],\n",
        "            y_pred  = predicciones)\n",
        "print(f\"El error (MAE) de test es: {mae_err}\")\n",
        "print(f\"El r2 de test es: {r2_err}\")"
      ],
      "metadata": {
        "id": "R5KaCNKvb8Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(22,5))\n",
        "plot_series(y_test.reset_index().index, y_test[target], \"True\")\n",
        "plot_series(y_test.reset_index().index, predicciones,'Predicted')\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.title('Sac_Campo true vs predicted')\n",
        "fig = plt.gcf()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig.savefig('true vs predic sac campo' + file + '.png', bboxs='tight')"
      ],
      "metadata": {
        "id": "Ef5RJI1-b8Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sac % Caña"
      ],
      "metadata": {
        "id": "QISVpHkacHUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'sac_caña_trans'\n",
        "grid.fit(X = X_train, y = y_train[target])"
      ],
      "metadata": {
        "id": "LEXrnt9gcKG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_sac = pd.DataFrame(grid.cv_results_)\n",
        "resultados_sac.filter(regex = '(param.*|mean_t|std_t)')\\\n",
        "    .drop(columns = 'params')\\\n",
        "    .sort_values('mean_test_score', ascending = False)\\\n",
        "    .head(3)"
      ],
      "metadata": {
        "id": "dy-sXE_0cKG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico resultados validación cruzada para cada hiperparámetro\n",
        "# ==============================================================================\n",
        "\n",
        "plot_error(resultados_sac)"
      ],
      "metadata": {
        "id": "Z8tqF9lVcKG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error de test del modelo final\n",
        "# ==============================================================================\n",
        "modelo_final = grid.best_estimator_\n",
        "predicciones = modelo_final.predict(X = X_test)\n",
        "mae_err = mean_absolute_error(\n",
        "            y_true  = y_test[target],\n",
        "            y_pred  = predicciones,\n",
        "          )\n",
        "r2_err = r2_score(y_true  = y_test[target],\n",
        "            y_pred  = predicciones)\n",
        "print(f\"El error (MAE) de test es: {mae_err}\")\n",
        "print(f\"El r2 de test es: {r2_err}\")"
      ],
      "metadata": {
        "id": "fCsKPOnicKG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(22,5))\n",
        "plot_series(y_test.reset_index().index, y_test[target], \"True\")\n",
        "plot_series(y_test.reset_index().index, predicciones,'Predicted')\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.title('Sac_%_Caña true vs predicted')\n",
        "fig = plt.gcf()\n",
        "plt.show()\n",
        "fig.savefig('true vs predic sac caña' + file + '.png', bboxs='tight')"
      ],
      "metadata": {
        "id": "SnWqfhU8cKG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}