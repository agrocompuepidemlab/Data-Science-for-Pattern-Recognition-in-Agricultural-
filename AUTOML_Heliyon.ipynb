{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QOItJz4MOW"
      },
      "source": [
        "# 1. Introduction\n",
        "---\n",
        "<h3>This notebook contains multiples machine learnings techniques (using AUTOML from PyCaret). Our dataset consist of weather and other variables corresponding to sugar cane crops, the goal is to predict values of sucrose production.</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFO2vf1N4yfW"
      },
      "source": [
        "# 2. Load Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "exnqmrra3tU8"
      },
      "outputs": [],
      "source": [
        "# Install and import Pycaret library\n",
        "!pip install numba==0.53\n",
        "!pip install pycaret\n",
        "# !pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m8bWGaJR4yCz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "from scipy import stats\n",
        "from scipy.stats import normaltest\n",
        "from sklearn.preprocessing import quantile_transform\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import libraries for visualization and set default values.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "plt.style.use(['seaborn'])\n",
        "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"tab10\"))\n",
        "sns.set_style('ticks')\n",
        "\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO_gdq9I48BG",
        "outputId": "539f32fe-bd3b-4177-b976-c53044a2e635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pycaret Version:  3.3.2\n"
          ]
        }
      ],
      "source": [
        "#Pycaret is used to automatomate machine learning workflow\n",
        "from pycaret.regression import *\n",
        "from pycaret.utils import version\n",
        "print('Pycaret Version: ', version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcuVCzmigwYX"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCcArNo07Kug"
      },
      "source": [
        "# 3. Load Dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxhHKPdc7P77",
        "outputId": "0a4c50ce-6284-44ee-b489-5b9bd45a11ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLkfKJ0S7WUn"
      },
      "outputs": [],
      "source": [
        "path='/Named_data.xlsx'\n",
        "weather_data_clean=pd.read_excel(path)\n",
        "file = ' ml no suelo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGpqY0zrgBuU"
      },
      "outputs": [],
      "source": [
        "weather_data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL6Xhvwk22-u"
      },
      "outputs": [],
      "source": [
        "weather_data_clean['PRODUCTO']=weather_data_clean['PRODUCTO'].replace(list(weather_data_clean.PRODUCTO.unique()), ['Producto '+str(i) for i in range(len(list(weather_data_clean.PRODUCTO.unique())))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQrwO_oALJ4"
      },
      "source": [
        "# 4. Normality\n",
        "---\n",
        "\n",
        "Perform a normality test on our target variables (*Sac, Sac Campo* and *Sac % Caña*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiRIGGz4AcTa"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize=(25,10))\n",
        "ax[0].hist(weather_data_clean['Sac'], color='r')\n",
        "ax[0].set_title('Histogram of Sac')\n",
        "ax[1].hist(weather_data_clean['Sac % Caña'],color='g')\n",
        "ax[1].set_title('Histogram of Sac % Caña')\n",
        "ax[2].hist(weather_data_clean['Sac Campo'])\n",
        "ax[2].set_title('Histogram of Sac Campo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTnJUWWtCS4g"
      },
      "outputs": [],
      "source": [
        "def normal_test(target):\n",
        "\tstat, p = normaltest(weather_data_clean[target])\n",
        "\talpha =0.05\n",
        "\tif p > alpha:\n",
        "\t\tprint(target + ' looks Gaussian')\n",
        "\telse:\n",
        "\t\tprint(target + ' does not look Gaussian')\n",
        "normal_test('Sac')\n",
        "normal_test('Sac % Caña')\n",
        "normal_test('Sac Campo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "150bCFuEEnK0"
      },
      "source": [
        "There is no conclusion about the normality.\n",
        "\n",
        "Using preprocessing techniques such as *Quantile transformation* we can normalize our targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkAdVateIG-n"
      },
      "outputs": [],
      "source": [
        "def normalization(target):\n",
        "    y=weather_data_clean[target]\n",
        "    y_trans = quantile_transform(y.to_frame(), output_distribution=\"normal\", copy=True)\n",
        "    return y_trans\n",
        "\n",
        "weather_data_clean['sac_trans'] = normalization('Sac')\n",
        "weather_data_clean['sac_caña_trans']= normalization('Sac % Caña')\n",
        "weather_data_clean['sac_campo_trans'] = normalization('Sac Campo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXP4MlZUIZgm"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize=(25,10))\n",
        "ax[0].hist(weather_data_clean['sac_trans'], color='r')\n",
        "ax[0].set_title('Histogram of Sac after transformation')\n",
        "ax[1].hist(weather_data_clean['sac_caña_trans'],color='g')\n",
        "ax[1].set_title('Histogram of Sac % Caña after transformation')\n",
        "ax[2].hist(weather_data_clean['sac_campo_trans'])\n",
        "ax[2].set_title('Histogram of Sac Campo after transformation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGJ7eSZYtnxx"
      },
      "source": [
        "Info about target variables after the transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwcGqABFtZ1L"
      },
      "outputs": [],
      "source": [
        "weather_data_clean[['sac_trans', 'sac_campo_trans', 'sac_caña_trans']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jFm2J5ouCvb"
      },
      "source": [
        "Testing normality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuAMhgZVHQC3",
        "outputId": "0942a6eb-7b35-486f-dabd-a38770fb8644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sac_trans looks Gaussian\n",
            "sac_caña_trans looks Gaussian\n",
            "sac_campo_trans looks Gaussian\n"
          ]
        }
      ],
      "source": [
        "normal_test('sac_trans')\n",
        "normal_test('sac_caña_trans')\n",
        "normal_test('sac_campo_trans')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1KJe-QElM3E"
      },
      "outputs": [],
      "source": [
        "weather_data_clean.drop(['Sac', 'Sac % Caña', 'Sac Campo'], axis=1, inplace=True) #remove old targets to left only normal targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjVWcLarxT2R"
      },
      "source": [
        "Our targets seem more normal.\n",
        "\n",
        "Split train and test set, later we create validation set. We are going to make a 70/20/10 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agEBa3Uf7Xku"
      },
      "outputs": [],
      "source": [
        "def dataset_pycaret(data_to_analyse):\n",
        "  dataset = data_to_analyse.copy()\n",
        "  data = dataset.sample(frac=0.90, random_state=786)\n",
        "  data_unseen = dataset.drop(data.index)\n",
        "  data.reset_index(inplace=True, drop=True)\n",
        "  data_unseen.reset_index(inplace=True, drop=True)\n",
        "  print('Data for Modeling: ' + str(data.shape))\n",
        "  print('Unseen Data For Predictions: ' + str(data_unseen.shape))\n",
        "  return [data,data_unseen]\n",
        "\n",
        "data, data_unseen=dataset_pycaret(weather_data_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyMqaw5Hh-Pu"
      },
      "source": [
        "For the next part of this notebook we are going to train different models for each of our target variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEHYYzqkk6Gw"
      },
      "source": [
        "# Sac variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qLH3jggqUmJ"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Using PyCaret we are going to setup out machine learning workflow. Our dependent variables are normalized using min-max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUu-Ubs21XQF"
      },
      "outputs": [],
      "source": [
        "reg_trans = setup(data=data, target = 'sac_trans',train_size=0.80,\n",
        "                ignore_features = ['sac_caña_trans','sac_campo_trans'],\n",
        "                categorical_features =['tmprda','TIPO COS','Con Sin Mad','nm_cndcion','PRODUCTO','VAR'],\n",
        "                rare_level_threshold = 0.1, combine_rare_levels = True,\n",
        "                remove_multicollinearity = True, multicollinearity_threshold = 0.95,\n",
        "                ignore_low_variance = True, normalize=True, normalize_method='minmax',\n",
        "                remove_outliers=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6lKJ0YTqMim"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeiKZM3Nqa5T"
      },
      "source": [
        "Train multiples models and choosing the best three (sorted using $r^2$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqcxuTlZKBJO"
      },
      "outputs": [],
      "source": [
        "best_trans = compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lct9BNPaq7og"
      },
      "source": [
        "We are going to use Light Gradient Boosting Machine, Extra Trees Regressor and Random Forest Regressor to create a blend model.\n",
        "\n",
        "Let's look some info about our LGBM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNrje_RvI6kQ"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='residuals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iQMJx3hLGuF"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnttRAq4LMgH"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='feature')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixiqUH5hnXT-"
      },
      "source": [
        "## Blend Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxSQDt1QnXT-"
      },
      "source": [
        "Create our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-iFXuInnXT_"
      },
      "outputs": [],
      "source": [
        "lgbm_model_sac = create_model('lightgbm')\n",
        "lgbm_model_sac = tune_model(lgbm_model_sac, n_iter=2)\n",
        "et_model_sac = create_model('et')\n",
        "et_model_sac = tune_model(et_model_sac, n_iter=2)\n",
        "rf_model_sac = create_model('rf')\n",
        "rf_model_sac = tune_model(rf_model_sac, n_iter=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U6GnGyEnXT_"
      },
      "source": [
        "Create blended model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y74C6pnNnXUA"
      },
      "outputs": [],
      "source": [
        "tuned_model_sac = blend_models(estimator_list=[lgbm_model_sac, rf_model_sac, et_model_sac], choose_better=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL_QdyJ3nXUA"
      },
      "source": [
        "Hyperparameter tunning of the blended model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPOkU4UInXUB"
      },
      "source": [
        "Some metrics about our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA7l5meNnXUB"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac, plot='residuals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oEZkdq-nXUC"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac, plot='error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-W997OQnXUC"
      },
      "source": [
        "Finalized model and save model in the file sac_caña_model.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z55cIB9-nXUD"
      },
      "outputs": [],
      "source": [
        "final_sac = finalize_model(tuned_model_sac)\n",
        "# save_model(final_sac, 'sac_model' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVS6OnoEnXUD"
      },
      "source": [
        "## Predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMQB9sCKnXUD"
      },
      "outputs": [],
      "source": [
        "test_data = data_unseen.drop(['sac_trans', 'sac_caña_trans', 'sac_campo_trans'], axis=1)\n",
        "test_pred = predict_model(final_sac, data = test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxg9G3kvnXUE"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series,i, format=\"-\", start=0, end=None):\n",
        "    #plt.figure(figsize=(20,10))\n",
        "    plt.plot(time[start:end], series[start:end], format,label=i)\n",
        "    plt.xlabel(\"Unseen Samples\")\n",
        "    plt.ylabel(\"Sucrose Field\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.figure(figsize=(22,5))\n",
        "plot_series(data_unseen.index, data_unseen['sac_trans'],\"True\")\n",
        "plot_series(data_unseen.index, test_pred['Label'],'Predicted')\n",
        "plt.grid(False)\n",
        "plt.title('Sac true vs predicted')\n",
        "fig = plt.gcf()\n",
        "plt.show()\n",
        "fig.savefig('true vs predic sac' + file + '.png', bboxs='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL0gLHdPdfjK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Aw3IqyVW4Zg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "r_score = r2_score(y_pred = test_pred['Label'], y_true = data_unseen['sac_trans'])\n",
        "mae_score = mean_absolute_error(y_pred = test_pred['Label'], y_true = data_unseen['sac_trans'])\n",
        "print('r2 en test set: {}'.format(r_score))\n",
        "print('mae en test set: {}'.format(mae_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT_98ZtTAsOe"
      },
      "source": [
        "# Sac Campo variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrFvA_TDA9_i"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Using PyCaret we are going to setup out machine learning workflow. Our dependent variables are normalized using min-max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m48FKIUA9_i"
      },
      "outputs": [],
      "source": [
        "reg_trans = setup(data=data, target = 'sac_campo_trans',train_size=0.80,\n",
        "                ignore_features = ['sac_caña_trans','sac_trans'],\n",
        "                categorical_features =['tmprda','TIPO COS','Con Sin Mad','nm_cndcion','PRODUCTO','VAR'],\n",
        "                rare_level_threshold = 0.1, combine_rare_levels = True,\n",
        "                remove_multicollinearity = True, multicollinearity_threshold = 0.95,\n",
        "                ignore_low_variance = True, normalize=True, normalize_method='minmax',\n",
        "                remove_outliers=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1JT51PQA9_i"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvY5eSEYA9_i"
      },
      "source": [
        "Train multiples models and choosing the best three (sorted using $r^2$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZF7QJ-uA9_j"
      },
      "outputs": [],
      "source": [
        "best_trans = compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSVkI6S6A9_j"
      },
      "source": [
        "We are going to use Light Gradient Boosting Machine, Extra Trees Regressor and Random Forest Regressor to create a blend model.\n",
        "\n",
        "Let's look some info about our ET model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MRizHS8A9_j"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='residuals')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnswGgqaCafc"
      },
      "source": [
        "It looks overfitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVlSHabXA9_j"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8baV6TI9A9_j"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='feature')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAE5GWX-dAjm"
      },
      "source": [
        "## Blend Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PWDRiTadAjn"
      },
      "source": [
        "Create our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIojvz01dAjn"
      },
      "outputs": [],
      "source": [
        "lgbm_model_sac_campo = create_model('lightgbm')\n",
        "et_model_sac_campo = create_model('et')\n",
        "rf_model_sac_campo = create_model('rf')\n",
        "lgbm_model_sac_campo = tune_model(lgbm_model_sac_campo, n_iter=2)\n",
        "#et_model_sac_campo = tune_model(et_model_sac_campo, n_iter=1)\n",
        "#rf_model_sac_campo = tune_model(rf_model_sac_campo, n_iter=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exRamXuXdAjn"
      },
      "source": [
        "Create blended model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYEASBH-dAjo"
      },
      "outputs": [],
      "source": [
        "tuned_model_sac_campo = blend_models(estimator_list=[lgbm_model_sac_campo, rf_model_sac_campo, et_model_sac_campo], choose_better=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBdrcR5JdAjo"
      },
      "source": [
        "Hyperparameter tunning of the blended model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDQ6-WGMdAjo"
      },
      "source": [
        "Some metrics about our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY32z2EGdAjo"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac_campo, plot='residuals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0DzOdWodAjo"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac_campo, plot='error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0o9qWD5dAjp"
      },
      "source": [
        "Finalized model and save model in the file sac_caña_model.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "941ytfrJdAjp"
      },
      "outputs": [],
      "source": [
        "final_sac_campo = finalize_model(tuned_model_sac_campo)\n",
        "#save_model(final_sac_campo, 'sac_campo_model' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk0NVu-ddAjp"
      },
      "source": [
        "## Predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQgCXT8PdAjp"
      },
      "outputs": [],
      "source": [
        "test_data = data_unseen.drop(['sac_trans', 'sac_caña_trans', 'sac_campo_trans'], axis=1)\n",
        "test_pred = predict_model(final_sac_campo, data = test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjtI5IGYdAjp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(22,5))\n",
        "plot_series(data_unseen.index, data_unseen['sac_campo_trans'],\"True\")\n",
        "plot_series(data_unseen.index, test_pred['Label'],'Predicted')\n",
        "plt.grid(False)\n",
        "plt.title('Sac_Campo true vs predicted')\n",
        "fig = plt.gcf()\n",
        "plt.show()\n",
        "fig.savefig('true vs predic sac campo' + file + '.png', bboxs='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67EeI0qkXPpo",
        "outputId": "e5df4721-1697-4743-8340-6f0d0ddae4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r2 en test set: 0.44980347049614566\n",
            "mae en test set: 0.5543422898333494\n"
          ]
        }
      ],
      "source": [
        "r_score = r2_score(y_pred = test_pred['Label'], y_true = data_unseen['sac_campo_trans'])\n",
        "mae_score = mean_absolute_error(y_pred = test_pred['Label'], y_true = data_unseen['sac_campo_trans'])\n",
        "print('r2 en test set: {}'.format(r_score))\n",
        "print('mae en test set: {}'.format(mae_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8eWKKK7dAjp"
      },
      "source": [
        "The model seems to fit great, however the target variable has many extreme values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHWWxo_ZODav"
      },
      "source": [
        "# Sac % Caña variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba0BcO4kOOsi"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Using PyCaret we are going to setup out machine learning workflow. Our dependent variables are normalized using min-max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dlj7bNqOOsj"
      },
      "outputs": [],
      "source": [
        "reg_trans = setup(data=data, target = 'sac_caña_trans',train_size=0.80,\n",
        "                ignore_features = ['sac_campo_trans','sac_trans'],\n",
        "                categorical_features =['tmprda','TIPO COS','Con Sin Mad','nm_cndcion','PRODUCTO','VAR'],\n",
        "                rare_level_threshold = 0.1, combine_rare_levels = True,\n",
        "                remove_multicollinearity = True, multicollinearity_threshold = 0.95,\n",
        "                ignore_low_variance = True, normalize=True, normalize_method='minmax',\n",
        "                remove_outliers=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD5Dg4qHOOsj"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8YOmGYiOOsj"
      },
      "source": [
        "Train multiples models and choosing the best three (sorted using $r^2$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTJ2I40eOOsj"
      },
      "outputs": [],
      "source": [
        "best_trans = compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApJ3wtfBOOsj"
      },
      "source": [
        "We are going to use Light Gradient Boosting Machine, Extra Trees Regressor and Random Forest Regressor to create a blend model.\n",
        "\n",
        "Let's look some info about our ET model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9TFV2v_OOsj"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='residuals')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAXcTNGZOOsk"
      },
      "source": [
        "It looks overfitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BBljDcCOOsk"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3aVBu3OOOsk"
      },
      "outputs": [],
      "source": [
        "plot_model(best_trans, plot='feature')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fJMu9SGHg3c"
      },
      "source": [
        "## Blend Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laQwFvazOOsk"
      },
      "source": [
        "Create our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcAuvkIrOOsk"
      },
      "outputs": [],
      "source": [
        "lgbm_model_sac_caña = create_model('lightgbm')\n",
        "et_model_sac_caña = create_model('et')\n",
        "rf_model_sac_caña = create_model('rf')\n",
        "lgbm_model_sac_caña = tune_model(lgbm_model_sac_caña, n_iter=2)\n",
        "et_model_sac_caña = tune_model(et_model_sac_caña, n_iter=2)\n",
        "rf_model_sac_caña = tune_model(rf_model_sac_caña, n_iter=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEf2WWZtYL2X"
      },
      "source": [
        "Create blended model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OTk4hXuIVM_"
      },
      "outputs": [],
      "source": [
        "tuned_model_sac_caña = blend_models(estimator_list=[lgbm_model_sac_caña, rf_model_sac_caña, et_model_sac_caña], choose_better=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH1iiiTnYXWg"
      },
      "source": [
        "Hyperparameter tunning of the blended model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1l8vdLJYbFJ"
      },
      "source": [
        "Some metrics about our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhJW8niFTNij"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac_caña, plot='residuals')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnBVovf4TNik"
      },
      "outputs": [],
      "source": [
        "plot_model(tuned_model_sac_caña, plot='error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c84psJqWYe-p"
      },
      "source": [
        "Finalized model and save model in the file sac_caña_model.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063dBWdrUK_l"
      },
      "outputs": [],
      "source": [
        "final_sac_caña = finalize_model(tuned_model_sac_caña)\n",
        "# save_model(final_sac_caña, 'sac_caña_model' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9_EkvuGYlQ0"
      },
      "source": [
        "## Predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td-qNj8PYqY5"
      },
      "outputs": [],
      "source": [
        "test_data = data_unseen.drop(['sac_trans', 'sac_caña_trans', 'sac_campo_trans'], axis=1)\n",
        "test_pred = predict_model(final_sac_caña, data = test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LReSK-tWZzTT"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series,i,c, format=\"-\", start=0, end=None):\n",
        "    #plt.figure(figsize=(20,10))\n",
        "    plt.plot(time[start:end], series[start:end], format,label=i, color=c)\n",
        "    plt.xlabel(\"Unseen Samples\")\n",
        "    plt.ylabel(\"Sucrose Field\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.figure(figsize=(22,5))\n",
        "plot_series(data_unseen.index, data_unseen['sac_caña_trans'],\"True\",'tab:blue')\n",
        "plot_series(data_unseen.index, test_pred['Label'],'Predicted','tab:orange')\n",
        "plt.grid(False)\n",
        "plt.title('Sac_%_Caña true vs predicted')\n",
        "fig = plt.gcf()\n",
        "plt.show()\n",
        "fig.savefig('true vs predic sac caña' + file + '.png', bboxs='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8ScIhC3XTk6"
      },
      "outputs": [],
      "source": [
        "r_score = r2_score(y_pred = test_pred['Label'], y_true = data_unseen['sac_caña_trans'])\n",
        "mae_score = mean_absolute_error(y_pred = test_pred['Label'], y_true = data_unseen['sac_caña_trans'])\n",
        "print('r2 en test set: {}'.format(r_score))\n",
        "print('mae en test set: {}'.format(mae_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvphyjNVdiVF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}